# Papers Simplified: Sequence To Sequence Learning With Neural Networks

## Encoder-Decoder: The Principle


Input Sequence -> Multilayer LSTM -> Fixed-Length Vector -> Multilayer LSTM -> Target Sequence

This is the language-as-sequence approach, where MT is taken to be the task of mapping a source sequence to a target sequence.




